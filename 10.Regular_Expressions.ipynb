{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка текстов\n",
    "\n",
    "## Регулярные выражения\n",
    "\n",
    "Часто возникает задача поиска в тексте каких-то элементов (например гиперссылок) или проверки введенных пользоватем данных. Для упрощения этих задач можно использовать регулярные выражения, реализация которых присутствует в стандартных библиотеках большей части популярных языков программирования, в том числе и в `Python`.\n",
    "\n",
    "Наиболее типичные сценария использования:\n",
    "\n",
    "* поиск паттерна в строке\n",
    "* проверка строки на совпадение паттерну \n",
    "* сегментация строки по паттерну \n",
    "* замена паттерна в строке.\n",
    "\n",
    "Паттерн описывается с помощью специального языка - регулярного выражения, в `Python` используются регулярные выражения со следующими базовыми наборами правил:\n",
    "\n",
    "|           |                       |              |                               |\n",
    "|-----------|-----------------------|--------------|-------------------------------|\n",
    "| .         | любой символ          | \\\\d          | цифра                         |\n",
    "| \\\\D       | не цифра              | \\\\s          | пробельный символ             |\n",
    "| \\\\S       | не пробельный символ  | \\\\w          | буквенный символ              |\n",
    "| \\\\W       | не буквенный символ   | ^            | начало строки                 |\n",
    "| $         | конец строки          | \\\\b          | начало слова                  |\n",
    "| \\\\B       | конец слова           | \\[abc\\]      | символ из перечисленных       |\n",
    "| \\[^abc\\]  | кроме символов        | \\[a\\-zA\\-Z\\] | символы из интервалов         |\n",
    "| X\\|Y      | или                   |\n",
    "\n",
    "\n",
    "Наборы символов и символьных классов можно объединять в группы, наподобие того как это происходит в обычных математических выражениях.  Для описания групп с различными целями существует следующие конструкции\n",
    "\n",
    "|           |                      |           |                           |\n",
    "|-----------|----------------------|-----------|---------------------------|\n",
    "| \\(X\\)     | группа \\(capturing\\) | \\(?:X\\)   | группа \\(non\\-capturing\\) |\n",
    "| \\(?=X\\)   | предпросмотр         | \\(?\\!X\\)  | негативный предпросмотр   |\n",
    "\n",
    "Квантификатор после какого-то подвыражения (символа или группы) позволяет задать правила повторения этого подвыражения. Квантификатор может относиться более чем к одному символу в регулярном выражении только если это группа.  В `Python` определены жадные квантификаторы \n",
    "\n",
    "|          |                       |           |                          |\n",
    "|----------|-----------------------|-----------|--------------------------|\n",
    "| X?       | 0 или 1 повторение    | X\\*       | $\\geq0$ повторений       |\n",
    "| X\\+      | $\\geq 1$ повторений   | X\\{n\\}    | ровно $n$ повторений     |\n",
    "| X\\{n,\\}  | $\\geq n$ повторений   | X\\{n,m\\}  | от $n$ до $m$ повторений |\n",
    "\n",
    "\n",
    "и ленивые квантификаторы\n",
    "\n",
    "|          |                       |           |                          |\n",
    "|----------|-----------------------|-----------|--------------------------|\n",
    "| X??      | 0 или 1 повторение    | X\\*?      | $\\geq0$ повторений       |\n",
    "| X\\+?     | $\\geq 1$ повторений   | X\\{n\\}?   | ровно $n$ повторений     |\n",
    "| X\\{n,\\}? | $\\geq n$ повторений   | X\\{n,m\\}? | от $n$ до $m$ повторений |\n",
    "\n",
    "Разница заключается в алгоритме сопоставления - жадные квантификаторы пытаются сопоставить как можно больше символов входной строки, ленивые - как можно меньше.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализации регулярных выражений\n",
    "\n",
    "### Формальные языки\n",
    "\n",
    "**Формальный язык** — множество конечных слов над конечным алфавитом $\\Sigma$. \n",
    "Пусть есть некоторое конечно множество символов $\\Sigma$, тогда множество $L \\in \\Sigma^*$ есть формальный язык. \n",
    "\n",
    "Над формальными языками можно определить операции:\n",
    "\n",
    "* $L_1 \\cap L_2$\n",
    "* $L_1 \\cup L_2$\n",
    "* $L_1 \\setminus L_2$\n",
    "* $L_1 \\cdot L_2 $ - новый язык, в котором ко всем возможным словам из $L_1$ присоеденены справа слова из $L_2$\n",
    "* $L^*$ - замыкание клини, $\\{\\epsilon\\} \\cup L \\cup (L \\cdot L) \\cup (L \\cdot L \\cdot L) \\cup \\cdots$\n",
    "\n",
    "Формальный язык над алфавитом $\\Sigma$ является **регулярным**, если он принадлежит множеству языков $R \\in \\Sigma^*$:\n",
    "\n",
    "* $\\varnothing \\in R$\n",
    "* $\\{\\varepsilon\\} \\in R$\n",
    "* $\\forall a \\in \\Sigma: \\{a\\} \\in R$\n",
    "* $P \\in R \\land Q \\in R \\Rightarrow (P \\cup Q) \\in R$\n",
    "* $P \\in R \\land Q \\in R \\Rightarrow (P \\cdot Q) \\in R$\n",
    "* $P \\in R \\Rightarrow P^* \\in R$\n",
    "\n",
    "Любой регулярный язык может быть описан:\n",
    "\n",
    "* детерменированным конечным автоматом\n",
    "* недетерменированным конечным автоматом\n",
    "* регулярным выражением\n",
    "* регулярном грамматикой\n",
    "\n",
    "**Конечные автоматы**\n",
    "\n",
    "Конечный автомат это упорядоченная пятерка $A = (\\Sigma, Q, q_0, F, \\delta)$, где\n",
    "\n",
    "* $\\Sigma$ - входной алфавит\n",
    "* $Q$ - множество состояний\n",
    "* $q_0 \\in Q$ - начальное состояние\n",
    "* $F \\subset Q$ - множество конечных состояний\n",
    "* $\\delta: (\\Sigma \\cup \\varepsilon) \\times Q \\rightarrow 2^Q$ - функция перехода\n",
    "\n",
    "В зависимости от определения функции перехода:\n",
    "\n",
    "* недетерминированный конечный автомат с $\\varepsilon$-переходами ($\\varepsilon$-NFA)\n",
    "$$\\delta: (\\Sigma \\cup \\varepsilon) \\times Q \\rightarrow 2^Q$$ \n",
    "* недетерминированный конечный автомат (NFA)\n",
    "$$\\delta: \\Sigma \\times Q \\rightarrow 2^Q$$ \n",
    "* детерминированный конечный автомат (DFA)\n",
    "$$\\delta: \\Sigma \\times Q \\rightarrow Q$$ \n",
    "\n",
    "Множество слов, которые принимаются конечным автоматом образуют регулярный язык. По любому $\\varepsilon$-NFA можно построить эквивалентный DFA. В DFA можно минимизировать число состояний. \n",
    "\n",
    "Графическое отображение конечного автомата представлено на изображении\n",
    "\n",
    "![конечный автомат](images/dfa.svg)\n",
    "\n",
    "\n",
    "Существует два распространенных способа реализации регулярных выражений, применяемых в различных задачах (не считая гибридов и т.п.):\n",
    "\n",
    "1. регулярное выражение -> $\\varepsilon$-NFA -> DFA -> min-DFA\n",
    "2. backtracking \n",
    "\n",
    "В стандартных библиотеках популярных языков программирования применяется backracking.\n",
    "\n",
    "## Разновидности синтаксиса регулярных выражений\n",
    "\n",
    "Исторически существует несколько возможных  синтаксисов языков для описания регулярных выражений\n",
    "\n",
    "* POSIX RE[@posix-re-ref] (`., *, [ ], [^ ], \\{ \\}, \\( \\)`)\n",
    "* POSIX ERE (`., *, +, ?, |, [ ], [^ ], { }, ( )`)\n",
    "* PCRE[@pcre-ref] (стандартные библиотеки `Perl`, `Java`, `C#`, `Python`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация в языке Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `Python` стандартные регулярные выражения определены в модуле `re`. Кроме того, существует специальный синтаксис задания строк для регулярных выражений - префикс `r`. В строках с этим префиксом не требуется специальным образом задавать специальные управляющие символы (например, `,`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендует сначала скомпилировать регулярное выражение с помощью функции `re.compile()`, в результате получится специальный объект, который можно использовать для выполнения основных задач"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'a+a$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, чтобы проверить совпадает ли паттерн, заданный регулярным выражением, со строкой, можно использовать метод `fullmatch`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(0, 4), match='aaaa'>\n"
     ]
    }
   ],
   "source": [
    "print(pattern.fullmatch('aaaa'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае строка `'aaaa'` соответствует паттерну `'a+a$'`, возвращается объект специального типа. Если соответствия нет, то возвращается `None`.\n",
    "\n",
    "Второй возможный сценарий использования - поиск непересекающихся подстрок, которые соответствую паттерну. Введем паттерн - все слова из букв *a* которые заканчиваются на *b*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'a+b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем все вхождения этого паттерна в строке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaab', 'ab']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'Hello aaab world ab !'\n",
    "pattern.findall(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё один сценарий - разделение строки на подстроки по паттерну. Это бывает полезным, когда нужно быстро разделить, например, предложения на слова, убрав все знаки препинания. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello ', ' world ', ' !']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern.split(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий сценарий использования - замена вхождений паттерна в строке.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello e world e !'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern.sub('e', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "В качестве замены можно передать не только строку, но и `lambda`-функцию, которая будет вызываться на каждое совпадение с образцом. В данном случае мы добавляем к каждому совпадению букву *a*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello aaaba world aba !'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern.sub(lambda x: x.group(0) + 'a', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Приведем более сложный пример. В качестве паттерна опишем адрес электронной почты (упрощенный, данный паттерн не удовлетворяет спецификации).Дальше разобьем этот адрес на составляющие:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test@example.com\n",
      "test\n",
      "example\n",
      "com\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(r'(\\w+)@(\\w+)\\.(\\w{2,3})')\n",
    "\n",
    "matcher = pattern.match('test@example.com')\n",
    "if matcher:\n",
    "    print(matcher.group(0))\n",
    "    print(matcher.group(1))\n",
    "    print(matcher.group(2))\n",
    "    print(matcher.group(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно найти все вхождения электронной почты в тексте и напечатать только домены первого уровня:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example.com\n",
      "gmail.com\n"
     ]
    }
   ],
   "source": [
    "t = 'test@example.com ssss test2@gmail.com'\n",
    "\n",
    "pattern = re.compile(r'(\\w+)@((\\w+)\\.(\\w{2,3}))')\n",
    "for m in pattern.finditer(t):\n",
    "    print (m.group(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "или имена пользователей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "s = 'test@example.com hello@mail.ru'\n",
    "matchers = pattern.finditer(s)\n",
    "for matcher in matchers:\n",
    "    print (matcher.group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратим внимание на работу жадных и ленивых квантификаторов. В случае применения жадных результат может быть не тем, что ожидается\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<h1> text1 </h1>  <h2> text3 </h2>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '<h1> text1 </h1>  <h2> text3 </h2>'\n",
    "re.findall(r'<\\w+>(?:.+)</\\w+>', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае можно использовать ленивые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<h1> text1 </h1>', '<h2> text3 </h2>']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'<\\w+>(?:.+?)</\\w+>', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё один важный момент касается производительности движка регулярных выражений. Так как в `Python` регулярные выражения реализованы через механизм backtracking'а, то в некоторых случаях можно получить экспоненциальную сложность. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'(a*a*)*c', 'a' * 10 + 'e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В модуле `re` есть недокументированный класс `Scanner`, с помощью которого можно реализовать лексический анализатор. `Scanner` будет искать вхождения паттернов в тексте и на каждое совпадение вызывать соответствующую функцию. В общем случае подобный код неэффективен, лексические анализаторы лучше реализовывать с помощью специальных инструментов - генераторов лексических анализаторов, которые обеспечат анализ за линейное время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('hello', 'word'),\n",
       "  (',', 'preposition'),\n",
       "  (' ', 'whitespace'),\n",
       "  ('world', 'word'),\n",
       "  (' ', 'whitespace'),\n",
       "  ('1234', 'digit'),\n",
       "  (' ', 'whitespace'),\n",
       "  ('test@example.com', 'email')],\n",
       " '')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanner = re.Scanner(\n",
    "   [(r'(\\w+)@(\\w+)\\.(\\w{2,3})', lambda s, x: (x, 'email')),\n",
    "    (r'[a-zA-Z]+', lambda s, x: (x, 'word')), \n",
    "    (r'\\d+', lambda s, x: (x, 'digit')),    \n",
    "    (r'\\s+', lambda s, x: (x, 'whitespace')),\n",
    "    (r'[.,;\"!?:]', lambda s, x: (x, 'preposition')),\n",
    "    ])\n",
    "\n",
    "scanner.scan('hello, world 1234 test@example.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструменты для обработки текстов\n",
    "\n",
    "Привидем список некоторых полезных библиотек для обработки текстовых данных:\n",
    "\n",
    "- ply(`Python`) - библиотека для написания лексических анализаторов на `Python`\n",
    "- pyparsing] (`Python`) - библиотека для написания синтаксических анализаторов на `Python`\n",
    "- lex, flex (`C`) - классические библиотеки - генераторы лексических анализаторов \n",
    "- jflex (`Java`) - библиотека для написания лексических анализаторов на `Java` \n",
    "- ANTLR(`Java`, `C++`, `Python`)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK\n",
    "Natural Language Toolkit, библиотека для обработки естественных языков.Она создавалась для учебных целей, но тем не менее приобрела определенную популярность. Например в ней реализовано множество методов токенизации, которые можно использовать для повседневных задач и экспериментов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alex/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Hello', 'world', '4.2', '.'],\n",
       " ['LA', 'New-York'],\n",
       " ['Hello', 'world', '4', '.', '2', '!'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize, word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "(word_tokenize('Hello world 4.2.'), \n",
    " word_tokenize('LA New-York'), \n",
    " wordpunct_tokenize('Hello world 4.2!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем лексического анализатора на `ply`. В данном случае анализатор описывается в классе, могут быть три вида токенов - слова, цифры и пробелы. Для каждого токена в тексте выозвращается необходимая информация - типа, длина смещение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LexToken(NUMBER,123,1,0)\n",
      "LexToken(ID,'abs',1,4)\n",
      "LexToken(NUMBER,965,1,8)\n"
     ]
    }
   ],
   "source": [
    "from ply.lex import lex, TOKEN\n",
    "\n",
    "class Lexer:\n",
    "    tokens = ( 'NUMBER', 'ID', 'WHITESPACE' )\n",
    "    \n",
    "    @TOKEN(r'\\d{1,5}')\n",
    "    def t_NUMBER(self, t):\n",
    "        t.value = int(t.value)\n",
    "        return t\n",
    "\n",
    "    @TOKEN(r'\\w+')\n",
    "    def t_ID(self, t):\n",
    "        return t\n",
    "\n",
    "    @TOKEN(r'\\s+')\n",
    "    def t_WHITESPACE(self, t):\n",
    "        pass\n",
    "\n",
    "    def t_error(self, t):\n",
    "        pass\n",
    "    \n",
    "\n",
    "__file__ = ''     # make `ply` happy\n",
    "\n",
    "lexer = lex(object=Lexer())\n",
    "lexer.input('123 abs 965')\n",
    "for token in lexer:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyparsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой пример `pyparsing`, с помощью которого можно обрабатывать более широкий класс формальных языков. С помощью специального DSL (domain-specific language, предметно-ориентированный язык) описывается грамматика. С помощью `pyparsing` можно обрабатывать коллекции в специфичных форматах, извлекать логи и так далее:\n",
    "\n",
    "В данном примере грамматика описывает строку, которая начинается со слова, после которого идет двоеточие и набор чисел через запятую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['hello', '1', '22', '3'], {})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyparsing import Word, alphas, nums,  Literal, StringEnd, ZeroOrMore, Suppress, OneOrMore \n",
    "\n",
    "word = Word(alphas)\n",
    "num = Word(nums)\n",
    "sep = Suppress(OneOrMore(','))\n",
    "col = Suppress(':')\n",
    "\n",
    "s = word + col + num + ZeroOrMore(sep + num) + StringEnd()\n",
    "        \n",
    "s.parseString('hello: 1, 22, 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь более сложный пример, грамматика описывает правильные скобочные записи.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['(', '(', ')', ')', '(', ')', '(', ')'], {})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyparsing import Literal, Forward, StringEnd, OneOrMore, Empty\n",
    "\n",
    "br_o = Literal('(')\n",
    "br_c = Literal(')')\n",
    "\n",
    "braces = Forward()\n",
    "braces << OneOrMore(br_o + (braces | Empty() ) + br_c)\n",
    "start = braces + StringEnd()\n",
    "        \n",
    "start.parseString('(())()()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И, наконец, простейшие математические выражения с приоритетом операций. Сначала можно определить классы, которые будут узлами дерева выражения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyparsing import Word, Literal, Or, nums, Forward, StringEnd\n",
    "from operator import mul, truediv, add, sub\n",
    "\n",
    "class NumNode(object):\n",
    "    def __init__(self, t):\n",
    "        self.num = float(t[0])        \n",
    "    def calc(self):\n",
    "        return self.num          \n",
    "    def __repr__(self):\n",
    "        return 'Num(%s)' % self.num\n",
    "        \n",
    "class OpNode(object):\n",
    "    def __init__(self, t):               \n",
    "        self.left = t[0]\n",
    "        self.op = { '-' : sub, '+' : add, '/' : truediv, '*' : mul }[t[1]]\n",
    "        self.right = t[2]       \n",
    "    def calc(self):\n",
    "        return self.op(self.left.calc(), self.right.calc())        \n",
    "    def __repr__(self):\n",
    "        return 'Op(%s, %s, %s)' % (self.left, self.op, self.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишем грамматику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus = Literal('+')\n",
    "minus = Literal('-')\n",
    "div = Literal('/')\n",
    "mult = Literal('*')\n",
    "        \n",
    "factor = Word(nums).setParseAction(NumNode)\n",
    "\n",
    "term = Forward()\n",
    "term << (( factor + (mult | div) + term ).setParseAction(OpNode) | factor )        \n",
    "\n",
    "expr = Forward()\n",
    "expr << ((term + (plus | minus) + expr).setParseAction(OpNode) | term )\n",
    "\n",
    "start = expr + StringEnd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Op(Op(Num(2.0), <built-in function mul>, Num(4.0)), <built-in function add>, Op(Num(6.0), <built-in function mul>, Num(7.0)))\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "tree = start.parseString('2 * 4 + 6 * 7')[0]\n",
    "print(tree)\n",
    "print(tree.calc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JFlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package ru.spbu.apmath.pt.lexer;\n",
      "\n",
      "import java.io.IOException;\n",
      "import ru.spbu.apmath.pt.lexer.TokenTypes;\n",
      "\n",
      "\n",
      "%%\n",
      "\n",
      "%class TestScanner\n",
      "%public\n",
      "%unicode\n",
      "%ignorecase\n",
      "%type TokenTypes\n",
      "%function getNextToken\n",
      "%pack\n",
      "%char\n",
      "\n",
      "%{\n",
      "\n",
      "\n",
      "public String getText() {\n",
      "    return yytext();\n",
      "}\n",
      "\n",
      "public int getCurPosistion() {\n",
      "    return yylength();\n",
      "}\n",
      "\n",
      "%}\n",
      "\n",
      "ALPHA = [a-zA-Z]\n",
      "DIGIT = [0-9]\n",
      "\n",
      "\n",
      "COMMENT   = \"/*\"  ~\"*/\"\n",
      "\n",
      "IDENTIFIER = {ALPHA} ({ALPHA} | {DIGIT})*\n",
      "\n",
      "INTEGER = 0 | [1-9][0-9]*\n",
      "\n",
      "\n",
      "%%\n",
      "\n",
      "<YYINITIAL> {\n",
      "    {IDENTIFIER} { return TokenTypes.TOKEN_IDENTIFIER; }\n",
      "    {INTEGER} { return TokenTypes.TOKEN_INTEGER; }\n",
      "    {COMMENT} {  }\n",
      "    . {    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat code/jflex/src/main/jflex/TestScanner.jflex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* The following code was generated by JFlex 1.4.3 on 14.10.13 21:58 */\n",
      "\n",
      "package ru.spbu.apmath.pt.lexer;\n",
      "\n",
      "import java.io.IOException;\n",
      "import ru.spbu.apmath.pt.lexer.TokenTypes;\n",
      "\n",
      "\n",
      "\n",
      "/**\n",
      " * This class is a scanner generated by \n",
      " * <a href=\"http://www.jflex.de/\">JFlex</a> 1.4.3\n",
      " * on 14.10.13 21:58 from the specification file\n",
      " * <tt>C:/Users/alms/home/work/asp/compilers/lexer/src/main/jflex/TestScanner.jflex</tt>\n",
      " */\n",
      "public class TestScanner {\n",
      "\n",
      "  /** This character denotes the end of file */\n",
      "  public static final int YYEOF = -1;\n",
      "\n",
      "  /** initial size of the lookahead buffer */\n",
      "  private static final int ZZ_BUFFERSIZE = 16384;\n",
      "\n",
      "  /** lexical states */\n",
      "  public static final int YYINITIAL = 0;\n",
      "\n",
      "  /**\n",
      "   * ZZ_LEXSTATE[l] is the state in the DFA for the lexical state l\n",
      "   * ZZ_LEXSTATE[l+1] is the state in the DFA for the lexical state l\n",
      "   *                  at the beginning of a line\n",
      "   * l is of the form l = 2*k, k a non negative integer\n",
      "   */\n",
      "  private static final int ZZ_LEXSTATE[] = { \n",
      "     0, 0\n",
      "  };\n",
      "\n",
      "  /** \n",
      "   * Translates characters to character classes\n",
      "   */\n",
      "  private static final String ZZ_CMAP_PACKED = \n",
      "    \"\\12\\0\\1\\6\\37\\0\\1\\4\\4\\0\\1\\3\\1\\5\\11\\2\\7\\0\\32\\1\"+\n",
      "    \"\\6\\0\\32\\1\\uff85\\0\";\n",
      "\n",
      "  /** \n",
      "   * Translates characters to character classes\n",
      "   */\n",
      "  private static final char [] ZZ_CMAP = zzUnpackCMap(ZZ_CMAP_PACKED);\n",
      "\n",
      "  /** \n",
      "   * Translates DFA states to action switch labels.\n",
      "   */\n",
      "  private static final int [] ZZ_ACTION = zzUnpackAction();\n",
      "\n",
      "  private static final String ZZ_ACTION_PACKED_0 =\n",
      "    \"\\1\\0\\1\\1\\1\\2\\1\\3\\1\\1\\1\\3\\2\\0\";\n",
      "\n",
      "  private static int [] zzUnpackAction() {\n",
      "    int [] result = new int[8];\n",
      "    int offset = 0;\n",
      "    offset = zzUnpackAction(ZZ_ACTION_PACKED_0, offset, result);\n",
      "    return result;\n",
      "  }\n",
      "\n",
      "  private static int zzUnpackAction(String packed, int offset, int [] result) {\n",
      "    int i = 0;       /* index in packed string  */\n",
      "    int j = offset;  /* index in unpacked array */\n",
      "    int l = packed.length();\n",
      "    while (i < l) {\n",
      "      int count = packed.charAt(i++);\n",
      "      int value = packed.charAt(i++);\n",
      "      do result[j++] = value; while (--count > 0);\n",
      "    }\n",
      "    return j;\n",
      "  }\n",
      "\n",
      "\n",
      "  /** \n",
      "   * Translates a state to a row index in the transition table\n",
      "   */\n",
      "  private static final int [] ZZ_ROWMAP = zzUnpackRowMap();\n",
      "\n",
      "  private static final String ZZ_ROWMAP_PACKED_0 =\n",
      "    \"\\0\\0\\0\\7\\0\\16\\0\\25\\0\\34\\0\\7\\0\\43\\0\\52\";\n",
      "\n",
      "  private static int [] zzUnpackRowMap() {\n",
      "    int [] result = new int[8];\n",
      "    int offset = 0;\n",
      "    offset = zzUnpackRowMap(ZZ_ROWMAP_PACKED_0, offset, result);\n",
      "    return result;\n",
      "  }\n",
      "\n",
      "  private static int zzUnpackRowMap(String packed, int offset, int [] result) {\n",
      "    int i = 0;  /* index in packed string  */\n",
      "    int j = offset;  /* index in unpacked array */\n",
      "    int l = packed.length();\n",
      "    while (i < l) {\n",
      "      int high = packed.charAt(i++) << 16;\n",
      "      result[j++] = high | packed.charAt(i++);\n",
      "    }\n",
      "    return j;\n",
      "  }\n",
      "\n",
      "  /** \n",
      "   * The transition table of the DFA\n",
      "   */\n",
      "  private static final int [] ZZ_TRANS = zzUnpackTrans();\n",
      "\n",
      "  private static final String ZZ_TRANS_PACKED_0 =\n",
      "    \"\\1\\2\\1\\3\\1\\4\\1\\5\\1\\2\\1\\6\\11\\0\\2\\3\"+\n",
      "    \"\\2\\0\\1\\3\\3\\0\\1\\4\\2\\0\\1\\4\\5\\0\\1\\7\"+\n",
      "    \"\\2\\0\\4\\7\\1\\10\\5\\7\\1\\2\\1\\10\\2\\7\";\n",
      "\n",
      "  private static int [] zzUnpackTrans() {\n",
      "    int [] result = new int[49];\n",
      "    int offset = 0;\n",
      "    offset = zzUnpackTrans(ZZ_TRANS_PACKED_0, offset, result);\n",
      "    return result;\n",
      "  }\n",
      "\n",
      "  private static int zzUnpackTrans(String packed, int offset, int [] result) {\n",
      "    int i = 0;       /* index in packed string  */\n",
      "    int j = offset;  /* index in unpacked array */\n",
      "    int l = packed.length();\n",
      "    while (i < l) {\n",
      "      int count = packed.charAt(i++);\n",
      "      int value = packed.charAt(i++);\n",
      "      value--;\n",
      "      do result[j++] = value; while (--count > 0);\n",
      "    }\n",
      "    return j;\n",
      "  }\n",
      "\n",
      "\n",
      "  /* error codes */\n",
      "  private static final int ZZ_UNKNOWN_ERROR = 0;\n",
      "  private static final int ZZ_NO_MATCH = 1;\n",
      "  private static final int ZZ_PUSHBACK_2BIG = 2;\n",
      "\n",
      "  /* error messages for the codes above */\n",
      "  private static final String ZZ_ERROR_MSG[] = {\n",
      "    \"Unkown internal scanner error\",\n",
      "    \"Error: could not match input\",\n",
      "    \"Error: pushback value was too large\"\n",
      "  };\n",
      "\n",
      "  /**\n",
      "   * ZZ_ATTRIBUTE[aState] contains the attributes of state <code>aState</code>\n",
      "   */\n",
      "  private static final int [] ZZ_ATTRIBUTE = zzUnpackAttribute();\n",
      "\n",
      "  private static final String ZZ_ATTRIBUTE_PACKED_0 =\n",
      "    \"\\1\\0\\1\\11\\3\\1\\1\\11\\2\\0\";\n",
      "\n",
      "  private static int [] zzUnpackAttribute() {\n",
      "    int [] result = new int[8];\n",
      "    int offset = 0;\n",
      "    offset = zzUnpackAttribute(ZZ_ATTRIBUTE_PACKED_0, offset, result);\n",
      "    return result;\n",
      "  }\n",
      "\n",
      "  private static int zzUnpackAttribute(String packed, int offset, int [] result) {\n",
      "    int i = 0;       /* index in packed string  */\n",
      "    int j = offset;  /* index in unpacked array */\n",
      "    int l = packed.length();\n",
      "    while (i < l) {\n",
      "      int count = packed.charAt(i++);\n",
      "      int value = packed.charAt(i++);\n",
      "      do result[j++] = value; while (--count > 0);\n",
      "    }\n",
      "    return j;\n",
      "  }\n",
      "\n",
      "  /** the input device */\n",
      "  private java.io.Reader zzReader;\n",
      "\n",
      "  /** the current state of the DFA */\n",
      "  private int zzState;\n",
      "\n",
      "  /** the current lexical state */\n",
      "  private int zzLexicalState = YYINITIAL;\n",
      "\n",
      "  /** this buffer contains the current text to be matched and is\n",
      "      the source of the yytext() string */\n",
      "  private char zzBuffer[] = new char[ZZ_BUFFERSIZE];\n",
      "\n",
      "  /** the textposition at the last accepting state */\n",
      "  private int zzMarkedPos;\n",
      "\n",
      "  /** the current text position in the buffer */\n",
      "  private int zzCurrentPos;\n",
      "\n",
      "  /** startRead marks the beginning of the yytext() string in the buffer */\n",
      "  private int zzStartRead;\n",
      "\n",
      "  /** endRead marks the last character in the buffer, that has been read\n",
      "      from input */\n",
      "  private int zzEndRead;\n",
      "\n",
      "  /** number of newlines encountered up to the start of the matched text */\n",
      "  private int yyline;\n",
      "\n",
      "  /** the number of characters up to the start of the matched text */\n",
      "  private int yychar;\n",
      "\n",
      "  /**\n",
      "   * the number of characters from the last newline up to the start of the \n",
      "   * matched text\n",
      "   */\n",
      "  private int yycolumn;\n",
      "\n",
      "  /** \n",
      "   * zzAtBOL == true <=> the scanner is currently at the beginning of a line\n",
      "   */\n",
      "  private boolean zzAtBOL = true;\n",
      "\n",
      "  /** zzAtEOF == true <=> the scanner is at the EOF */\n",
      "  private boolean zzAtEOF;\n",
      "\n",
      "  /** denotes if the user-EOF-code has already been executed */\n",
      "  private boolean zzEOFDone;\n",
      "\n",
      "  /* user code: */\n",
      "\n",
      "\n",
      "public String getText() {\n",
      "    return yytext();\n",
      "}\n",
      "\n",
      "public int getCurPosistion() {\n",
      "    return yylength();\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "  /**\n",
      "   * Creates a new scanner\n",
      "   * There is also a java.io.InputStream version of this constructor.\n",
      "   *\n",
      "   * @param   in  the java.io.Reader to read input from.\n",
      "   */\n",
      "  public TestScanner(java.io.Reader in) {\n",
      "    this.zzReader = in;\n",
      "  }\n",
      "\n",
      "  /**\n",
      "   * Creates a new scanner.\n",
      "   * There is also java.io.Reader version of this constructor.\n",
      "   *\n",
      "   * @param   in  the java.io.Inputstream to read input from.\n",
      "   */\n",
      "  public TestScanner(java.io.InputStream in) {\n",
      "    this(new java.io.InputStreamReader(in));\n",
      "  }\n",
      "\n",
      "  /** \n",
      "   * Unpacks the compressed character translation table.\n",
      "   *\n",
      "   * @param packed   the packed character translation table\n",
      "   * @return         the unpacked character translation table\n",
      "   */\n",
      "  private static char [] zzUnpackCMap(String packed) {\n",
      "    char [] map = new char[0x10000];\n",
      "    int i = 0;  /* index in packed string  */\n",
      "    int j = 0;  /* index in unpacked array */\n",
      "    while (i < 26) {\n",
      "      int  count = packed.charAt(i++);\n",
      "      char value = packed.charAt(i++);\n",
      "      do map[j++] = value; while (--count > 0);\n",
      "    }\n",
      "    return map;\n",
      "  }\n",
      "\n",
      "\n",
      "  /**\n",
      "   * Refills the input buffer.\n",
      "   *\n",
      "   * @return      <code>false</code>, iff there was new input.\n",
      "   * \n",
      "   * @exception   java.io.IOException  if any I/O-Error occurs\n",
      "   */\n",
      "  private boolean zzRefill() throws java.io.IOException {\n",
      "\n",
      "    /* first: make room (if you can) */\n",
      "    if (zzStartRead > 0) {\n",
      "      System.arraycopy(zzBuffer, zzStartRead,\n",
      "                       zzBuffer, 0,\n",
      "                       zzEndRead-zzStartRead);\n",
      "\n",
      "      /* translate stored positions */\n",
      "      zzEndRead-= zzStartRead;\n",
      "      zzCurrentPos-= zzStartRead;\n",
      "      zzMarkedPos-= zzStartRead;\n",
      "      zzStartRead = 0;\n",
      "    }\n",
      "\n",
      "    /* is the buffer big enough? */\n",
      "    if (zzCurrentPos >= zzBuffer.length) {\n",
      "      /* if not: blow it up */\n",
      "      char newBuffer[] = new char[zzCurrentPos*2];\n",
      "      System.arraycopy(zzBuffer, 0, newBuffer, 0, zzBuffer.length);\n",
      "      zzBuffer = newBuffer;\n",
      "    }\n",
      "\n",
      "    /* finally: fill the buffer with new input */\n",
      "    int numRead = zzReader.read(zzBuffer, zzEndRead,\n",
      "                                            zzBuffer.length-zzEndRead);\n",
      "\n",
      "    if (numRead > 0) {\n",
      "      zzEndRead+= numRead;\n",
      "      return false;\n",
      "    }\n",
      "    // unlikely but not impossible: read 0 characters, but not at end of stream    \n",
      "    if (numRead == 0) {\n",
      "      int c = zzReader.read();\n",
      "      if (c == -1) {\n",
      "        return true;\n",
      "      } else {\n",
      "        zzBuffer[zzEndRead++] = (char) c;\n",
      "        return false;\n",
      "      }     \n",
      "    }\n",
      "\n",
      "\t// numRead < 0\n",
      "    return true;\n",
      "  }\n",
      "\n",
      "    \n",
      "  /**\n",
      "   * Closes the input stream.\n",
      "   */\n",
      "  public final void yyclose() throws java.io.IOException {\n",
      "    zzAtEOF = true;            /* indicate end of file */\n",
      "    zzEndRead = zzStartRead;  /* invalidate buffer    */\n",
      "\n",
      "    if (zzReader != null)\n",
      "      zzReader.close();\n",
      "  }\n",
      "\n",
      "\n",
      "  /**\n",
      "   * Resets the scanner to read from a new input stream.\n",
      "   * Does not close the old reader.\n",
      "   *\n",
      "   * All internal variables are reset, the old input stream \n",
      "   * <b>cannot</b> be reused (internal buffer is discarded and lost).\n",
      "   * Lexical state is set to <tt>ZZ_INITIAL</tt>.\n",
      "   *\n",
      "   * @param reader   the new input stream \n",
      "   */\n",
      "  public final void yyreset(java.io.Reader reader) {\n",
      "    zzReader = reader;\n",
      "    zzAtBOL  = true;\n",
      "    zzAtEOF  = false;\n",
      "    zzEOFDone = false;\n",
      "    zzEndRead = zzStartRead = 0;\n",
      "    zzCurrentPos = zzMarkedPos = 0;\n",
      "    yyline = yychar = yycolumn = 0;\n",
      "    zzLexicalState = YYINITIAL;\n",
      "  }\n",
      "\n",
      "\n",
      "  /**\n",
      "   * Returns the current lexical state.\n",
      "   */\n",
      "  public final int yystate() {\n",
      "    return zzLexicalState;\n",
      "  }\n",
      "\n",
      "\n",
      "  /**\n",
      "   * Enters a new lexical state\n",
      "   *\n",
      "   * @param newState the new lexical state\n",
      "   */\n",
      "  public final void yybegin(int newState) {\n",
      "    zzLexicalState = newState;\n",
      "  }\n",
      "\n",
      "\n",
      "  /**\n",
      "   * Returns the text matched by the current regular expression.\n",
      "   */\n",
      "  public final String yytext() {\n",
      "    return new String( zzBuffer, zzStartRead, zzMarkedPos-zzStartRead );\n",
      "  }\n",
      "\n",
      "\n",
      "  /**\n",
      "   * Returns the character at position <tt>pos</tt> from the \n",
      "   * matched text. \n",
      "   * \n",
      "   * It is equivalent to yytext().charAt(pos), but faster\n",
      "   *\n",
      "   * @param pos the position of the character to fetch. \n",
      "   *            A value from 0 to yylength()-1.\n",
      "   *\n",
      "   * @return the character at position pos\n",
      "   */\n",
      "  public final char yycharat(int pos) {\n",
      "    return zzBuffer[zzStartRead+pos];\n",
      "  }\n",
      "\n",
      "\n",
      "  /**\n",
      "   * Returns the length of the matched text region.\n",
      "   */\n",
      "  public final int yylength() {\n",
      "    return zzMarkedPos-zzStartRead;\n",
      "  }\n",
      "\n",
      "\n",
      "  /**\n",
      "   * Reports an error that occured while scanning.\n",
      "   *\n",
      "   * In a wellformed scanner (no or only correct usage of \n",
      "   * yypushback(int) and a match-all fallback rule) this method \n",
      "   * will only be called with things that \"Can't Possibly Happen\".\n",
      "   * If this method is called, something is seriously wrong\n",
      "   * (e.g. a JFlex bug producing a faulty scanner etc.).\n",
      "   *\n",
      "   * Usual syntax/scanner level error handling should be done\n",
      "   * in error fallback rules.\n",
      "   *\n",
      "   * @param   errorCode  the code of the errormessage to display\n",
      "   */\n",
      "  private void zzScanError(int errorCode) {\n",
      "    String message;\n",
      "    try {\n",
      "      message = ZZ_ERROR_MSG[errorCode];\n",
      "    }\n",
      "    catch (ArrayIndexOutOfBoundsException e) {\n",
      "      message = ZZ_ERROR_MSG[ZZ_UNKNOWN_ERROR];\n",
      "    }\n",
      "\n",
      "    throw new Error(message);\n",
      "  } \n",
      "\n",
      "\n",
      "  /**\n",
      "   * Pushes the specified amount of characters back into the input stream.\n",
      "   *\n",
      "   * They will be read again by then next call of the scanning method\n",
      "   *\n",
      "   * @param number  the number of characters to be read again.\n",
      "   *                This number must not be greater than yylength()!\n",
      "   */\n",
      "  public void yypushback(int number)  {\n",
      "    if ( number > yylength() )\n",
      "      zzScanError(ZZ_PUSHBACK_2BIG);\n",
      "\n",
      "    zzMarkedPos -= number;\n",
      "  }\n",
      "\n",
      "\n",
      "  /**\n",
      "   * Resumes scanning until the next regular expression is matched,\n",
      "   * the end of input is encountered or an I/O-Error occurs.\n",
      "   *\n",
      "   * @return      the next token\n",
      "   * @exception   java.io.IOException  if any I/O-Error occurs\n",
      "   */\n",
      "  public TokenTypes getNextToken() throws java.io.IOException {\n",
      "    int zzInput;\n",
      "    int zzAction;\n",
      "\n",
      "    // cached fields:\n",
      "    int zzCurrentPosL;\n",
      "    int zzMarkedPosL;\n",
      "    int zzEndReadL = zzEndRead;\n",
      "    char [] zzBufferL = zzBuffer;\n",
      "    char [] zzCMapL = ZZ_CMAP;\n",
      "\n",
      "    int [] zzTransL = ZZ_TRANS;\n",
      "    int [] zzRowMapL = ZZ_ROWMAP;\n",
      "    int [] zzAttrL = ZZ_ATTRIBUTE;\n",
      "\n",
      "    while (true) {\n",
      "      zzMarkedPosL = zzMarkedPos;\n",
      "\n",
      "      yychar+= zzMarkedPosL-zzStartRead;\n",
      "\n",
      "      zzAction = -1;\n",
      "\n",
      "      zzCurrentPosL = zzCurrentPos = zzStartRead = zzMarkedPosL;\n",
      "  \n",
      "      zzState = ZZ_LEXSTATE[zzLexicalState];\n",
      "\n",
      "\n",
      "      zzForAction: {\n",
      "        while (true) {\n",
      "    \n",
      "          if (zzCurrentPosL < zzEndReadL)\n",
      "            zzInput = zzBufferL[zzCurrentPosL++];\n",
      "          else if (zzAtEOF) {\n",
      "            zzInput = YYEOF;\n",
      "            break zzForAction;\n",
      "          }\n",
      "          else {\n",
      "            // store back cached positions\n",
      "            zzCurrentPos  = zzCurrentPosL;\n",
      "            zzMarkedPos   = zzMarkedPosL;\n",
      "            boolean eof = zzRefill();\n",
      "            // get translated positions and possibly new buffer\n",
      "            zzCurrentPosL  = zzCurrentPos;\n",
      "            zzMarkedPosL   = zzMarkedPos;\n",
      "            zzBufferL      = zzBuffer;\n",
      "            zzEndReadL     = zzEndRead;\n",
      "            if (eof) {\n",
      "              zzInput = YYEOF;\n",
      "              break zzForAction;\n",
      "            }\n",
      "            else {\n",
      "              zzInput = zzBufferL[zzCurrentPosL++];\n",
      "            }\n",
      "          }\n",
      "          int zzNext = zzTransL[ zzRowMapL[zzState] + zzCMapL[zzInput] ];\n",
      "          if (zzNext == -1) break zzForAction;\n",
      "          zzState = zzNext;\n",
      "\n",
      "          int zzAttributes = zzAttrL[zzState];\n",
      "          if ( (zzAttributes & 1) == 1 ) {\n",
      "            zzAction = zzState;\n",
      "            zzMarkedPosL = zzCurrentPosL;\n",
      "            if ( (zzAttributes & 8) == 8 ) break zzForAction;\n",
      "          }\n",
      "\n",
      "        }\n",
      "      }\n",
      "\n",
      "      // store back cached position\n",
      "      zzMarkedPos = zzMarkedPosL;\n",
      "\n",
      "      switch (zzAction < 0 ? zzAction : ZZ_ACTION[zzAction]) {\n",
      "        case 2: \n",
      "          { return TokenTypes.TOKEN_IDENTIFIER;\n",
      "          }\n",
      "        case 4: break;\n",
      "        case 3: \n",
      "          { return TokenTypes.TOKEN_INTEGER;\n",
      "          }\n",
      "        case 5: break;\n",
      "        case 1: \n",
      "          { \n",
      "          }\n",
      "        case 6: break;\n",
      "        default: \n",
      "          if (zzInput == YYEOF && zzStartRead == zzCurrentPos) {\n",
      "            zzAtEOF = true;\n",
      "            return null;\n",
      "          } \n",
      "          else {\n",
      "            zzScanError(ZZ_NO_MATCH);\n",
      "          }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "\n",
      "\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat code/jflex/src/main/java/ru/spbu/apmath/pt/lexer/TestScanner.java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package ru.spbu.apmath.pt.lexer;\n",
      "\n",
      "import java.io.StringReader;\n",
      "\n",
      "public class LexerExample {\n",
      "\n",
      "    public static void main(String[] args) throws Exception {\n",
      "        //Разбиваем строку на токены (комментарии игнорируем).\n",
      "        final String exampleText = \"hello world 2012 /* comment */ \";\n",
      "\n",
      "        final TestScanner scanner = new TestScanner(new StringReader(exampleText));\n",
      "\n",
      "        TokenTypes token = null;\n",
      "        while ((token = scanner.getNextToken()) != null) {\n",
      "            System.out.println(token + \" \" + scanner.getText() + \" \" + scanner.getCurPosistion());\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat code/jflex/src/main/java/ru/spbu/apmath/pt/lexer/LexerExample.java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
